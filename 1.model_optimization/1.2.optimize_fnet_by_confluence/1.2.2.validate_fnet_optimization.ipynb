{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook the FNet optimization results are validating against train and heldout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "import yaml\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import mlflow\n",
    "import mlflow.artifacts\n",
    "import optuna\n",
    "from optuna.visualization import plot_param_importances, plot_optimization_history\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pathlib.Path('.').absolute().parent.parent / \"config.yml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import virtual_stain_flow software "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(config['paths']['software_path'])\n",
    "print(str(pathlib.Path('.').absolute().parent.parent))\n",
    "\n",
    "## Dataset\n",
    "from virtual_stain_flow.datasets.PatchDataset import PatchDataset\n",
    "from virtual_stain_flow.datasets.CachedDataset import CachedDataset\n",
    "\n",
    "## FNet training\n",
    "from virtual_stain_flow.models.fnet import FNet\n",
    "from virtual_stain_flow.trainers.Trainer import Trainer\n",
    "\n",
    "## wGaN training\n",
    "from virtual_stain_flow.models.unet import UNet\n",
    "from virtual_stain_flow.models.discriminator import GlobalDiscriminator\n",
    "from virtual_stain_flow.trainers.WGaNTrainer import WGaNTrainer\n",
    "\n",
    "## wGaN losses\n",
    "from virtual_stain_flow.losses.GradientPenaltyLoss import GradientPenaltyLoss\n",
    "from virtual_stain_flow.losses.DiscriminatorLoss import DiscriminatorLoss\n",
    "from virtual_stain_flow.losses.GeneratorLoss import GeneratorLoss\n",
    "\n",
    "from virtual_stain_flow.transforms.MinMaxNormalize import MinMaxNormalize\n",
    "from virtual_stain_flow.transforms.PixelDepthTransform import PixelDepthTransform\n",
    "\n",
    "## Metrics\n",
    "from virtual_stain_flow.metrics.MetricsWrapper import MetricsWrapper\n",
    "from virtual_stain_flow.metrics.PSNR import PSNR\n",
    "from virtual_stain_flow.metrics.SSIM import SSIM\n",
    "\n",
    "## callback\n",
    "from virtual_stain_flow.callbacks.MlflowLogger import MlflowLogger\n",
    "from virtual_stain_flow.callbacks.IntermediatePlot import IntermediatePatchPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define paths and other train parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loaddata for train and heldout set\n",
    "LOADDATA_FILE_PATH = pathlib.Path('.').absolute().parent.parent \\\n",
    "    / '0.data_preprocessing' / 'data_split_loaddata' / 'loaddata_train.csv'\n",
    "assert LOADDATA_FILE_PATH.exists()\n",
    "LOADDATA_EVAL_FILE_PATH = pathlib.Path('.').absolute().parent.parent \\\n",
    "    / '0.data_preprocessing' / 'data_split_loaddata' / 'loaddata_heldout.csv'\n",
    "assert LOADDATA_EVAL_FILE_PATH.exists()\n",
    "\n",
    "## Corresponding sc features directory containing cell coordiantes used for patch generation\n",
    "SC_FEATURES_DIR = pathlib.Path(config['paths']['sc_features_path'])\n",
    "\n",
    "## Optimization Output Saved under these directories\n",
    "MLFLOW_DIR = pathlib.Path('.').absolute() / 'optuna_mlflow'\n",
    "assert MLFLOW_DIR.exists()\n",
    "\n",
    "OPTUNA_JOBLIB_DIR = pathlib.Path('.').absolute() / 'optuna_joblib'\n",
    "assert OPTUNA_JOBLIB_DIR.exists()\n",
    "\n",
    "## Validation Output Path\n",
    "VALIDATION_OUTPUT_PATH = pathlib.Path('.').absolute() / 'Validation'\n",
    "VALIDATION_OUTPUT_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "## Patch size definition\n",
    "PATCH_SIZE = 256\n",
    "\n",
    "## Channels for input and target are read from config\n",
    "INPUT_CHANNEL_NAMES = config['data']['input_channel_keys']\n",
    "TARGET_CHANNEL_NAMES = config['data']['target_channel_keys']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defines how the train data will be divided to train models on two levels of confluence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_GROUPING = {\n",
    "    'high_confluence': {\n",
    "        'seeding_density': [12_000, 8_000]\n",
    "    },\n",
    "    # 'low_confluence': {\n",
    "    #     'seeding_density': [4_000, 2_000, 1_000]\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(MLFLOW_DIR / 'mlruns')\n",
    "\n",
    "mlflow_results = {}\n",
    "optuna_results = defaultdict(dict)\n",
    "\n",
    "for confluence_group_name, _ in DATA_GROUPING.items():\n",
    "    ## Access relevant optimization result and logs by confluence\n",
    "    experiment_name = f'FNet_optimize_{confluence_group_name}'\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    mlflow_results[confluence_group_name] = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "    \n",
    "    for channel_name in TARGET_CHANNEL_NAMES:\n",
    "        optuna_study_path = OPTUNA_JOBLIB_DIR / f\"FNet_optimize_{channel_name}_{confluence_group_name}.joblib\"\n",
    "        study = joblib.load(optuna_study_path)\n",
    "        optuna_results[confluence_group_name][channel_name] = study\n",
    "\n",
    "        print(f\"Optuna study {channel_name} {confluence_group_name}:\")\n",
    "        plot_param_importances(study).show()\n",
    "        plot_optimization_history(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_results['high_confluence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from virtual_stain_flow.evaluation.plot_utils import plot_patches\n",
    "from virtual_stain_flow.evaluation.evaluation_utils import evaluate_per_image_metric\n",
    "from virtual_stain_flow.evaluation.predict_utils import predict_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_DEVICE = 'cpu'\n",
    "EVAL_METRICS = [PSNR(_metric_name='psnr'), SSIM(_metric_name='ssim')]\n",
    "\n",
    "## All validation results will be concatenated into this dataframe for convenience of comparison\n",
    "all_metrics_df = pd.DataFrame()\n",
    "\n",
    "## Iterate over train and heldout\n",
    "for datasplit, loaddata_df in zip(\n",
    "    ['train', 'heldout'], \n",
    "    [pd.read_csv(LOADDATA_FILE_PATH), pd.read_csv(LOADDATA_EVAL_FILE_PATH)]):\n",
    "\n",
    "    DATASPLIT_VALIDATION_PATH = VALIDATION_OUTPUT_PATH / datasplit\n",
    "    DATASPLIT_VALIDATION_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "    ## Iterate over confluence groups\n",
    "    for confluence_group_name, conditions in DATA_GROUPING.items():\n",
    "\n",
    "        CONFLUENCE_VALIDATION_PATH = DATASPLIT_VALIDATION_PATH / confluence_group_name\n",
    "        CONFLUENCE_VALIDATION_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "        ## Subset loaddata to confluence  group\n",
    "        loaddata_condition_df = loaddata_df.copy()\n",
    "        for condition, values in conditions.items():\n",
    "            loaddata_condition_df = loaddata_condition_df[\n",
    "                loaddata_condition_df[condition].isin(values)\n",
    "            ]\n",
    "\n",
    "        ## Collect corresponding sc features\n",
    "        sc_features = pd.DataFrame()\n",
    "        for plate in loaddata_condition_df['Metadata_Plate'].unique():\n",
    "            sc_features_parquet = SC_FEATURES_DIR / f'{plate}_sc_normalized.parquet'\n",
    "            if not sc_features_parquet.exists():\n",
    "                print(f'{sc_features_parquet} does not exist, skipping...')\n",
    "                continue \n",
    "            else:\n",
    "                sc_features = pd.concat([\n",
    "                    sc_features, \n",
    "                    pd.read_parquet(\n",
    "                        sc_features_parquet,\n",
    "                        columns=['Metadata_Plate', 'Metadata_Well', 'Metadata_Site', 'Metadata_Cells_Location_Center_X', 'Metadata_Cells_Location_Center_Y']\n",
    "                    )\n",
    "                ])\n",
    "\n",
    "        ## Load data\n",
    "        pds = PatchDataset(\n",
    "            _loaddata_csv=loaddata_condition_df,\n",
    "            _sc_feature=sc_features,\n",
    "            _input_channel_keys=INPUT_CHANNEL_NAMES,\n",
    "            _target_channel_keys=TARGET_CHANNEL_NAMES,\n",
    "            _input_transform=PixelDepthTransform(src_bit_depth=16, target_bit_depth=8, _always_apply=True),\n",
    "            _target_transform=MinMaxNormalize(_normalization_factor=(2 ** 16) - 1, _always_apply=True),\n",
    "            patch_size=PATCH_SIZE,\n",
    "            verbose=False,\n",
    "            patch_generation_method=\"random_cell\",\n",
    "            n_expected_patches_per_img=50,\n",
    "            patch_generation_random_seed=42\n",
    "        )\n",
    "\n",
    "        ## Group evaluation by channel (mostly unecessary)\n",
    "        for target_channel_name, df in mlflow_results[confluence_group_name].groupby('params.channel_name'):\n",
    "            \n",
    "            CHANNEL_VALIDATION_PATH = CONFLUENCE_VALIDATION_PATH / target_channel_name\n",
    "            CHANNEL_VALIDATION_PATH.mkdir(exist_ok=True)\n",
    "            \n",
    "            EXAMPLE_PATCH_PLOT_PATH = CHANNEL_VALIDATION_PATH / f'example_patch_plots'\n",
    "            EXAMPLE_PATCH_PLOT_PATH.mkdir(exist_ok=True)\n",
    "            \n",
    "            pds.set_input_channel_keys(INPUT_CHANNEL_NAMES)\n",
    "            pds.set_target_channel_keys([target_channel_name])\n",
    "            _, targets = next(iter(DataLoader(pds, batch_size=len(pds))))\n",
    "            \n",
    "            ## Iterate over models\n",
    "            for _, row in df.iterrows():\n",
    "                model_run_id = row['run_id']\n",
    "\n",
    "                METRICS_FILE_PATH = CHANNEL_VALIDATION_PATH / f'{model_run_id}_metrics.csv'\n",
    "                if METRICS_FILE_PATH.exists():\n",
    "                    metrics_df = pd.read_csv(METRICS_FILE_PATH)\n",
    "                    all_metrics_df = pd.concat([all_metrics_df, metrics_df])\n",
    "                    continue\n",
    "\n",
    "                model_uri = row['artifact_uri']\n",
    "                model_weight_path = pathlib.Path(mlflow.artifacts.download_artifacts(artifact_uri=model_uri)) /\\\n",
    "                    'models' / 'best_model_weights.pth'\n",
    "                if not model_weight_path.exists():\n",
    "                    print(f\"Model weight not found for run {model_run_id}, skipping ...\")\n",
    "                    continue\n",
    "                model_depth = int(row['params.depth'])\n",
    "                model_channel_name = row['params.channel_name']\n",
    "\n",
    "                model = FNet(depth=model_depth)\n",
    "                try:\n",
    "                    model.load_state_dict(torch.load(model_weight_path, weights_only=True))\n",
    "                except:\n",
    "                    print(f\"Fail to load model weight for run {model_run_id}, skipping ...\")\n",
    "                    continue\n",
    "                model.to(EVAL_DEVICE)\n",
    "                \n",
    "                predictions = predict_image(\n",
    "                    dataset = pds,\n",
    "                    model = model,\n",
    "                    device = EVAL_DEVICE\n",
    "                )\n",
    "\n",
    "                metrics_df = evaluate_per_image_metric(\n",
    "                    predictions=predictions,\n",
    "                    targets=targets,\n",
    "                    metrics=EVAL_METRICS\n",
    "                )\n",
    "                metrics_mean = metrics_df.mean()\n",
    "\n",
    "                metrics_df['datasplit'] = datasplit\n",
    "                metrics_df['confluence'] = confluence_group_name\n",
    "                params_values = {key: value for key, value in row.items() if key.startswith('params.')}\n",
    "                for param, value in params_values.items():\n",
    "                    metrics_df[param] = value\n",
    "                metrics_df.to_csv(METRICS_FILE_PATH)\n",
    "                all_metrics_df = pd.concat([all_metrics_df, metrics_df])\n",
    "                \n",
    "                metrics_mean_str = '_'.join([f\"{key}={value:.2f}\" for key, value in metrics_mean.items()])\n",
    "                params_str = '_'.join([f\"{key.replace('params.','')}={value}\" for key, value in params_values.items()])\n",
    "                plot_patches(\n",
    "                    dataset=pds,\n",
    "                    n_patches=5,\n",
    "                    model=model,\n",
    "                    random_seed=42,\n",
    "                    device=EVAL_DEVICE,\n",
    "                    metrics=EVAL_METRICS,\n",
    "                    show_plot=False,\n",
    "                    save_path=EXAMPLE_PATCH_PLOT_PATH / f'{metrics_mean_str}_{params_str}.png'\n",
    "                )                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speckle_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
